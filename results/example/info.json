{"model_name": "gpt2", "method": "decoding", "task_name": "Pereira_M02", "test_trail_ids": [0.2, 0.4], "valid_trail_ids": [0.2, 0.4], "random_number": 1, "batch_size": 2, "fmri_pca": true, "cuda": "0", "layer": -1, "num_epochs": 1, "lr": 0.0001, "dropout": 0.5, "brain_embed_size": 1000, "checkpoint_path": "../results/example", "load_check_point": false, "enable_grad": false, "mode": "all", "end2end_part": [-1.0, 2.0], "additional_loss": 0, "fake_input": 0, "add_end": false, "context": true, "roi_selected": [], "project_name": "decoding", "noise_ratio": 0.5, "wandb": "none", "generation_method": "beam", "pos": true, "output": "test", "data_spliting": "random", "loss": "continuation", "brain_model": "mlp", "weight_decay": 1.0, "l2": 0.0, "num_layers": 2, "evaluate_log": false, "normalized": false, "input_method": "normal", "activation": "relu", "pretrain_epochs": 1, "pretrain_lr": 0.001, "data_size": -1, "results_path": "results", "dataset_path": "../../dataset/", "shuffle_times": 10, "prev_mask_len": 32, "max_generate_len": 32, "early_stop": 10, "use_bad_words_ids": false, "repetition_penalty": 2.0, "ncontext": 10, "gcontext": 30, "use_decoder_vocab": true, "num_steps": 1000, "length_penalty": 0.3, "beam_width": 5, "extensions": 5, "llm_model_path": "../results/example"}